{
  "project": "RDI-AgentBeats-TheBulletproofProtocol",
  "description": "Legal Domain Agent Benchmark for AgentBeats competition - IRS Section 41 R&D tax credit evaluator. Purple agent (reference implementation) generates test narratives, Green agent (benchmark) evaluates them for IRS compliance.",
  "scope": "Phase 1 complete (STORY-001 to STORY-021). Phase 2 in progress (STORY-022 to STORY-043): Output alignment (P0), Arena mode, Hybrid evaluation, Benchmark rigor.",
  "source": "docs/PRD.md",
  "generated": "2026-01-25 17:40:47",
  "stories": [
    {
      "id": "STORY-001",
      "title": "Implement narrative generator",
      "description": "Generate IRS Section 41 compliant Four-Part Test narratives from engineering signals. - Implement narrative generator",
      "acceptance": [
        "Generates 500-word project summary focused on Process of Experimentation",
        "Follows Four-Part Test structure (Hypothesis, Test, Failure, Iteration)",
        "Filters business risk from technical risk",
        "Outputs structured narrative with technical uncertainty evidence",
        "Template-based generation (data ingestion out of scope)",
        "Python 3.13 compatible"
      ],
      "files": [
        "src/bulletproof_purple/generator.py",
        "src/bulletproof_purple/server.py"
      ],
      "passes": false,
      "completed_at": null,
      "content_hash": "58e0833418793e87aaa1f36f1d5479441c0a519c63fac27915dd2678e8462ff7",
      "depends_on": []
    },
    {
      "id": "STORY-002",
      "title": "Create Purple Agent server",
      "description": "Generate IRS Section 41 compliant Four-Part Test narratives from engineering signals. - Create Purple Agent server",
      "acceptance": [
        "Generates 500-word project summary focused on Process of Experimentation",
        "Follows Four-Part Test structure (Hypothesis, Test, Failure, Iteration)",
        "Filters business risk from technical risk",
        "Outputs structured narrative with technical uncertainty evidence",
        "Template-based generation (data ingestion out of scope)",
        "Python 3.13 compatible"
      ],
      "files": [
        "src/bulletproof_purple/generator.py",
        "src/bulletproof_purple/server.py"
      ],
      "passes": false,
      "completed_at": null,
      "content_hash": "e8c1bbbba18dcfce6acb9469e860d9e9f8db2fe689537372355dda4292b69781",
      "depends_on": [
        "STORY-001"
      ]
    },
    {
      "id": "STORY-003",
      "title": "Implement rule-based evaluator",
      "description": "Evaluate narratives against IRS Section 41 audit standards using rule-based detection. - Implement rule-based evaluator",
      "acceptance": [
        "Detects \"Routine Engineering\" patterns",
        "Applies \"Business Component\" test",
        "Flags vague language without specific metrics",
        "Requires citation of specific failure events",
        "Outputs Risk Score (0-100) and Redline Markup",
        "Rejects claims until Risk Score < 20",
        "Deterministic rule-based scoring",
        "Returns structured evaluation per Green-Agent-Metrics-Specification.md"
      ],
      "files": [
        "src/bulletproof_green/evaluator.py",
        "src/bulletproof_green/scorer.py",
        "src/bulletproof_green/server.py"
      ],
      "passes": false,
      "completed_at": null,
      "content_hash": "c2ee82deed7932970ad903dc477e7373781a38a46382c9707b0bdef1b6920354",
      "depends_on": []
    },
    {
      "id": "STORY-004",
      "title": "Implement scorer",
      "description": "Evaluate narratives against IRS Section 41 audit standards using rule-based detection. - Implement scorer",
      "acceptance": [
        "Detects \"Routine Engineering\" patterns",
        "Applies \"Business Component\" test",
        "Flags vague language without specific metrics",
        "Requires citation of specific failure events",
        "Outputs Risk Score (0-100) and Redline Markup",
        "Rejects claims until Risk Score < 20",
        "Deterministic rule-based scoring",
        "Returns structured evaluation per Green-Agent-Metrics-Specification.md"
      ],
      "files": [
        "src/bulletproof_green/evaluator.py",
        "src/bulletproof_green/scorer.py",
        "src/bulletproof_green/server.py"
      ],
      "passes": false,
      "completed_at": null,
      "content_hash": "0bac22a69cf83d3c55e174920b9009726eebe552c2fc5207a9b2bf5a20cc54ea",
      "depends_on": []
    },
    {
      "id": "STORY-005",
      "title": "Create Green Agent server",
      "description": "Evaluate narratives against IRS Section 41 audit standards using rule-based detection. - Create Green Agent server",
      "acceptance": [
        "Detects \"Routine Engineering\" patterns",
        "Applies \"Business Component\" test",
        "Flags vague language without specific metrics",
        "Requires citation of specific failure events",
        "Outputs Risk Score (0-100) and Redline Markup",
        "Rejects claims until Risk Score < 20",
        "Deterministic rule-based scoring",
        "Returns structured evaluation per Green-Agent-Metrics-Specification.md"
      ],
      "files": [
        "src/bulletproof_green/evaluator.py",
        "src/bulletproof_green/scorer.py",
        "src/bulletproof_green/server.py"
      ],
      "passes": false,
      "completed_at": null,
      "content_hash": "9d45a8e69577dc746ebee6428232148020116602b7d59ee435d6618e2a0ed251",
      "depends_on": [
        "STORY-003",
        "STORY-004"
      ]
    },
    {
      "id": "STORY-006",
      "title": "Create A2A messenger",
      "description": "Multi-turn orchestration where Green Agent iteratively refines Purple Agent narratives via A2A protocol. - Create A2A messenger",
      "acceptance": [
        "Green agent accepts `mode=arena` parameter",
        "Calls Purple Agent via A2A protocol for each iteration",
        "Loop terminates when risk_score < target OR max_iterations reached",
        "Returns ArenaResult with full iteration history",
        "Configurable max_iterations (default: 5) and target_risk_score (default: 20)",
        "A2A protocol integration",
        "Each iteration includes: narrative, evaluation, critique"
      ],
      "files": [
        "src/bulletproof_green/arena_executor.py",
        "src/bulletproof_green/messenger.py"
      ],
      "passes": false,
      "completed_at": null,
      "content_hash": "ba599c50179614dd5094ce948d97acd076effdf61bb4de4900ef6733cd784658",
      "depends_on": [
        "STORY-002",
        "STORY-005"
      ]
    },
    {
      "id": "STORY-007",
      "title": "Implement arena executor",
      "description": "Multi-turn orchestration where Green Agent iteratively refines Purple Agent narratives via A2A protocol. - Implement arena executor",
      "acceptance": [
        "Green agent accepts `mode=arena` parameter",
        "Calls Purple Agent via A2A protocol for each iteration",
        "Loop terminates when risk_score < target OR max_iterations reached",
        "Returns ArenaResult with full iteration history",
        "Configurable max_iterations (default: 5) and target_risk_score (default: 20)",
        "A2A protocol integration",
        "Each iteration includes: narrative, evaluation, critique"
      ],
      "files": [
        "src/bulletproof_green/arena_executor.py",
        "src/bulletproof_green/messenger.py"
      ],
      "passes": false,
      "completed_at": null,
      "content_hash": "1d73f95de8a22b0c7db892019a46624d96967c1a6a83d34f394ad4b6e01c5fa5",
      "depends_on": [
        "STORY-006"
      ]
    },
    {
      "id": "STORY-008",
      "title": "Implement LLM judge",
      "description": "Combine rule-based and LLM-based evaluation for reproducible scores with semantic understanding. - Implement LLM judge",
      "acceptance": [
        "Rule-based evaluation remains deterministic",
        "LLM-as-Judge provides semantic analysis with chain-of-thought reasoning",
        "Combined scoring: final_score = alpha*rule_score + beta*llm_score",
        "Fallback to rule-only if LLM unavailable",
        "LLM uses temperature=0 for consistency",
        "OpenAI GPT-4 for LLM judge",
        "Graceful degradation when LLM unavailable"
      ],
      "files": [
        "src/bulletproof_green/llm_judge.py",
        "src/bulletproof_green/evaluator.py"
      ],
      "passes": false,
      "completed_at": null,
      "content_hash": "f1d5288a768c39bf531c61563fd6688d9aee60f6addba52380cac8fe8e0099ab",
      "depends_on": [
        "STORY-003"
      ]
    },
    {
      "id": "STORY-009",
      "title": "Create ground truth dataset",
      "description": "Labeled dataset of narratives for benchmark validation and training. - Create ground truth dataset",
      "acceptance": [
        "20+ labeled narratives with expected scores",
        "Mix of passing (Risk Score < 20) and failing narratives",
        "Covers common failure patterns (vague language, business risk, routine engineering)",
        "Anonymized to protect client confidentiality",
        "JSON format for machine readability",
        "Human-readable annotations"
      ],
      "files": [
        "data/ground_truth.json",
        "src/validate_benchmark.py"
      ],
      "passes": false,
      "completed_at": null,
      "content_hash": "91bc778a0e16b7c00342e0ce1de170757502469bcf1833c6f07e51428dd6739e",
      "depends_on": []
    },
    {
      "id": "STORY-010",
      "title": "Implement benchmark validator",
      "description": "Labeled dataset of narratives for benchmark validation and training. - Implement benchmark validator",
      "acceptance": [
        "20+ labeled narratives with expected scores",
        "Mix of passing (Risk Score < 20) and failing narratives",
        "Covers common failure patterns (vague language, business risk, routine engineering)",
        "Anonymized to protect client confidentiality",
        "JSON format for machine readability",
        "Human-readable annotations"
      ],
      "files": [
        "data/ground_truth.json",
        "src/validate_benchmark.py"
      ],
      "passes": false,
      "completed_at": null,
      "content_hash": "877f8a91e687394b145b371b0324609a0f95c192d306dcc73e0d838879b94378",
      "depends_on": [
        "STORY-009"
      ]
    }
  ]
}