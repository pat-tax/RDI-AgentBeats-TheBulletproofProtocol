# Bulletproof Protocol - Environment Configuration Example
# Copy this file to .env and update with your actual values

# ============================================================================
# QUICK START
# ============================================================================
# 1. Copy this file:
#    cp .env.example .env
#
# 2. Set GREEN_OPENAI_API_KEY (required for LLM-based evaluation):
#    GREEN_OPENAI_API_KEY=sk-your-actual-key-here
#
# 3. Run agents:
#    docker-compose up -d
#    OR
#    python -m bulletproof_green.server  # Port 8000
#    python -m bulletproof_purple.server # Port 8001
#
# 4. Debug settings:
#    python -m bulletproof_green.settings
#    python -m bulletproof_purple.settings
#
# All settings have sensible defaults. Only GREEN_OPENAI_API_KEY is required
# for LLM features (system gracefully falls back to rule-only scoring without it).

# ============================================================================
# GREEN AGENT CONFIGURATION
# ============================================================================

# Server settings
# NOTE: These ports align with docker-compose-local.yml and settings.py defaults
GREEN_PORT=9009
GREEN_HOST=0.0.0.0
GREEN_TIMEOUT=300

# Purple Agent connection (for arena mode)
GREEN_PURPLE_AGENT_URL=http://localhost:9010

# Agent card settings
GREEN_AGENT_CARD_TIMEOUT=30
GREEN_AGENT_CARD_CACHE_TTL=300

# LLM Judge settings (for hybrid scoring)
# IMPORTANT: Required for LLM-based evaluation features

# Option 1: OpenAI (default)
GREEN_OPENAI_API_KEY=sk-your-key-here
# AGENTBEATS_LLM_BASE_URL defaults to https://api.openai.com/v1

# Option 2: Azure OpenAI
# GREEN_OPENAI_API_KEY=your-azure-key
# AGENTBEATS_LLM_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment
# AGENTBEATS_LLM_MODEL=gpt-4

# Option 3: Local model (Ollama, vLLM, LM Studio)
# GREEN_OPENAI_API_KEY=not-needed-for-local
# AGENTBEATS_LLM_BASE_URL=http://localhost:11434/v1  # Ollama
# AGENTBEATS_LLM_MODEL=llama3:8b

# Option 4: Other OpenAI-compatible API (Anthropic via proxy, etc.)
# GREEN_OPENAI_API_KEY=your-api-key
# AGENTBEATS_LLM_BASE_URL=https://your-proxy.com/v1
# AGENTBEATS_LLM_MODEL=claude-3-opus

# Model configuration
GREEN_LLM_MODEL=gpt-4
GREEN_LLM_TEMPERATURE=0.0
GREEN_LLM_ALPHA=0.7
GREEN_LLM_BETA=0.3
GREEN_LLM_TIMEOUT=30.0

# Arena mode settings
GREEN_ARENA_MAX_ITERATIONS=5
GREEN_ARENA_TARGET_RISK_SCORE=20

# ============================================================================
# PURPLE AGENT CONFIGURATION
# ============================================================================

# Server settings
# NOTE: These ports align with docker-compose-local.yml and settings.py defaults
PURPLE_PORT=9010
PURPLE_HOST=0.0.0.0
PURPLE_TIMEOUT=300

# ============================================================================
# USAGE NOTES
# ============================================================================
#
# 1. Copy this file to .env:
#    cp .env.example .env
#
# 2. Update GREEN_OPENAI_API_KEY with your actual OpenAI API key
#
# 3. Adjust ports if running multiple instances or if ports are in use
#
# 4. For production, review and adjust timeout values based on your needs
#
# 5. LLM Judge (hybrid scoring):
#    - If no API key is provided, system falls back to rule-only scoring
#    - Alpha (0.7) = weight for rule-based score
#    - Beta (0.3) = weight for LLM score
#    - Final score = alpha * rule_score + beta * llm_score
